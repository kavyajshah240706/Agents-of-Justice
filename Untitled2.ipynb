{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO/DOTqgwsW21Rcip80/dSj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavyajshah240706/Agents-of-Justice/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiLNJ1CJ5KlT",
        "outputId": "4f80c9db-ddec-49a8-a470-3b67114eb797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "The token `law2` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `law2`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_file.csv' with your actual CSV file path\n",
        "df = pd.read_csv('/content/cases.csv')\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETRqXIOX5XYq",
        "outputId": "5880294a-af50-4a4a-cff2-a804ae3aec8b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0        id                                               text\n",
            "0           0   1989_75  civil appellate jurisdiction civil appeal numb...\n",
            "1           1  1959_102  civil appellate jurisdiction civil appeal numb...\n",
            "2           2   1979_76  civil appellate jurisdiction civil appeal numb...\n",
            "3           3  1991_124  civil appellate jurisdiction civil appeal numb...\n",
            "4           4  1985_233  original jurisdiction writ petitions number. 8...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Optional\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "# === Generic Agent Class ===\n",
        "class CourtroomAgent:\n",
        "    def __init__(self,\n",
        "                 name: str,\n",
        "                 system_prompt: str,\n",
        "                 model: str = \"mistralai/Mistral-7B-v0.3\"):\n",
        "        self.name = name\n",
        "        self.system_prompt = system_prompt.strip()\n",
        "        self.history: List[Dict[str, str]] = []      # list of {\"role\": ..., \"content\": ...}\n",
        "        self.client = InferenceClient(\n",
        "            model,\n",
        "            token=os.getenv(\"law2\")           # make sure this env-var is set\n",
        "        )\n",
        "\n",
        "    def _format_prompt(self, user_msg: str) -> str:\n",
        "        messages = [{\"role\": \"system\", \"content\": self.system_prompt}]\n",
        "        # Limit history to last 4 messages to prevent token overflow\n",
        "        messages.extend(self.history[-2:])  # Keep only the most recent 4 messages\n",
        "        messages.append({\"role\": \"user\", \"content\": user_msg})\n",
        "\n",
        "        prompt = \"\"\n",
        "        for m in messages:\n",
        "            prompt += f\"<|{m['role']}|>\\n{m['content']}\\n\"\n",
        "        prompt += \"<|assistant|>\\n\"\n",
        "        return prompt\n",
        "\n",
        "    def respond(self, user_msg: str, verbose=False, **gen_kwargs) -> str:\n",
        "        prompt = self._format_prompt(user_msg)\n",
        "        completion = self.client.text_generation(\n",
        "            prompt,\n",
        "            max_new_tokens=512,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            stream=False,\n",
        "            **gen_kwargs\n",
        "        )\n",
        "        answer = completion.strip()\n",
        "        self.history.append({\"role\": \"user\", \"content\": user_msg})\n",
        "        self.history.append({\"role\": \"assistant\", \"content\": answer})\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\n{self.name}:\")\n",
        "            print(answer)\n",
        "\n",
        "        return answer\n",
        "\n",
        "# === Role Registry ===\n",
        "ROLE_REGISTRY = {\n",
        "    \"Defendant\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are the *Defendant*.\n",
        "Goals:\n",
        "• Present your side truthfully and calmly.\n",
        "• Refute allegations based on your experience and recollection.\n",
        "Style:\n",
        "• Honest, composed, assertive when needed.\n",
        "Ethics:\n",
        "• Speak only based on your memory and beliefs. Do not lie.\n",
        "\"\"\",\n",
        "        \"required\": True\n",
        "    },\n",
        "    \"Defense Lawyer\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are lead *defense counsel*.\n",
        "Goals:\n",
        "• Protect the constitutional rights of the defendant.\n",
        "• Raise reasonable doubt by pointing out missing evidence or alternative explanations.\n",
        "• Be respectful to the Court and to opposing counsel.\n",
        "Style:\n",
        "• Crisp, persuasive, grounded in precedent and facts provided.\n",
        "• When citing precedent: give short case name + year (e.g., *Miranda v. Arizona* (1966)).\n",
        "Ethics:\n",
        "• Do not fabricate evidence; admit uncertainty when required.\n",
        "\"\"\",\n",
        "        \"required\": True\n",
        "    },\n",
        "    \"Plaintiff\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are the *Plaintiff*.\n",
        "Goals:\n",
        "• Share your account of the incident in a clear and compelling manner.\n",
        "Style:\n",
        "• Personal, emotional, but grounded in facts.\n",
        "Ethics:\n",
        "• Tell the truth as you experienced it.\n",
        "\"\"\",\n",
        "        \"required\": True\n",
        "    },\n",
        "    \"Prosecution Lawyer\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are *Assistant District Attorney* for the State.\n",
        "Goals:\n",
        "• Present the strongest good-faith case against the accused.\n",
        "• Lay out facts logically, citing exhibits or witness statements when available.\n",
        "• Anticipate and rebut common defense arguments.\n",
        "Style:\n",
        "• Formal but plain English; persuasive, with confident tone.\n",
        "Ethics:\n",
        "• Duty is to justice, not merely to win. Concede points when ethically required.\n",
        "\"\"\",\n",
        "        \"required\": True\n",
        "    },\n",
        "    \"Judge\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are the presiding *Judge*.\n",
        "Goals:\n",
        "• Ensure a fair trial by evaluating the arguments, facts, and testimonies.\n",
        "• Make rational, legally sound rulings.\n",
        "Style:\n",
        "• Calm, authoritative, impartial.\n",
        "Ethics:\n",
        "• Maintain judicial neutrality and decorum at all times.\n",
        "At the end of your verdict, you must clearly state whether the case is GRANTED or DENIED. Use exactly this format at the end of your verdict: \"FINAL VERDICT: [GRANTED/DENIED]\"\n",
        "\"\"\",\n",
        "        \"required\": True\n",
        "    },\n",
        "    \"Witness\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are a *Witness* in the trial.\n",
        "Goals:\n",
        "• Provide truthful testimony based on your knowledge of the case.\n",
        "• Answer questions clearly and concisely.\n",
        "Style:\n",
        "• Neutral, factual, cooperative.\n",
        "Ethics:\n",
        "• Do not speculate or lie; stick to what you know.\n",
        "\"\"\",\n",
        "        \"required\": False,\n",
        "        \"spawn_condition\": \"witness\"\n",
        "    },\n",
        "    \"Expert Consultant\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are an *Expert Consultant* providing specialized knowledge.\n",
        "Goals:\n",
        "• Offer objective, evidence-based insights relevant to the case.\n",
        "• Explain complex topics clearly for the court.\n",
        "Style:\n",
        "• Professional, precise, academic.\n",
        "Ethics:\n",
        "• Remain impartial and avoid advocating for either side.\n",
        "\"\"\",\n",
        "        \"required\": False,\n",
        "        \"spawn_condition\": \"expert\"\n",
        "    },\n",
        "    \"Bailiff\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are the *Bailiff*.\n",
        "Goals:\n",
        "• Maintain courtroom order and assist the judge as needed.\n",
        "• Announce trial phases or call witnesses.\n",
        "Style:\n",
        "• Formal, direct, procedural.\n",
        "Ethics:\n",
        "• Follow court protocol strictly.\n",
        "\"\"\",\n",
        "        \"required\": False,\n",
        "        \"spawn_condition\": \"procedural\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# === Courtroom Simulation ===\n",
        "class CourtroomSimulation:\n",
        "    def __init__(self, case_background: str):\n",
        "        self.case_background = case_background\n",
        "        self.agents: Dict[str, CourtroomAgent] = {}\n",
        "        self.initialize_agents()\n",
        "        self.verdict = None\n",
        "\n",
        "    def initialize_agents(self):\n",
        "        \"\"\"Initialize required agents and dynamically spawn optional ones based on case.\"\"\"\n",
        "        # Spawn required agents\n",
        "        for role, config in ROLE_REGISTRY.items():\n",
        "            if config[\"required\"]:\n",
        "                self.agents[role] = CourtroomAgent(\n",
        "                    name=role,\n",
        "                    system_prompt=config[\"system_prompt\"]\n",
        "                )\n",
        "\n",
        "        # Analyze case for optional roles\n",
        "        self.spawn_optional_agents()\n",
        "\n",
        "    def spawn_optional_agents(self):\n",
        "        \"\"\"Dynamically spawn optional agents based on case background.\"\"\"\n",
        "        case_lower = self.case_background.lower()\n",
        "        for role, config in ROLE_REGISTRY.items():\n",
        "            if not config[\"required\"] and role not in self.agents:\n",
        "                spawn_condition = config.get(\"spawn_condition\", \"\")\n",
        "                if spawn_condition in case_lower:\n",
        "                    self.agents[role] = CourtroomAgent(\n",
        "                        name=role,\n",
        "                        system_prompt=config[\"system_prompt\"]\n",
        "                    )\n",
        "\n",
        "    def dismiss_agent(self, role: str):\n",
        "        \"\"\"Dismiss an agent when no longer needed.\"\"\"\n",
        "        if role in self.agents and not ROLE_REGISTRY[role][\"required\"]:\n",
        "            del self.agents[role]\n",
        "\n",
        "    def extract_verdict(self, judge_verdict: str) -> int:\n",
        "        \"\"\"Extract the binary verdict (GRANTED=1/DENIED=0) from the judge's text.\"\"\"\n",
        "        # Look for the FINAL VERDICT pattern\n",
        "        verdict_match = re.search(r\"FINAL VERDICT:\\s*(GRANTED|DENIED)\", judge_verdict, re.IGNORECASE)\n",
        "        if verdict_match:\n",
        "            verdict_text = verdict_match.group(1).upper()\n",
        "            return 1 if verdict_text == \"GRANTED\" else 0\n",
        "\n",
        "        # If no clear pattern, request clarification from Judge\n",
        "        clarification = self.agents[\"Judge\"].respond(\n",
        "            \"Clarify your verdict: Is the case GRANTED or DENIED? Please use the format: FINAL VERDICT: [GRANTED/DENIED]\"\n",
        "        )\n",
        "        verdict_match = re.search(r\"FINAL VERDICT:\\s*(GRANTED|DENIED)\", clarification, re.IGNORECASE)\n",
        "        if verdict_match:\n",
        "            verdict_text = verdict_match.group(1).upper()\n",
        "            return 1 if verdict_text == \"GRANTED\" else 0\n",
        "\n",
        "        # If still no clear verdict, use sentiment analysis as fallback\n",
        "        positive_terms = [\"granted\", \"approve\", \"in favor\", \"plaintiff wins\", \"rule for plaintiff\"]\n",
        "        negative_terms = [\"denied\", \"reject\", \"dismiss\", \"defendant wins\", \"rule for defendant\"]\n",
        "\n",
        "        positive_count = sum(judge_verdict.lower().count(term) for term in positive_terms)\n",
        "        negative_count = sum(judge_verdict.lower().count(term) for term in negative_terms)\n",
        "\n",
        "        return 1 if positive_count > negative_count else 0\n",
        "\n",
        "    def run_trial(self, verbose=False) -> int:\n",
        "        \"\"\"Run the trial with dynamic phase handling and return binary verdict.\"\"\"\n",
        "        if verbose:\n",
        "            print(\"==== Courtroom Trial ====\")\n",
        "            print(f\"Case Background: {self.case_background}\\n\")\n",
        "            print(\"==== Opening Statements ====\")\n",
        "\n",
        "        # Opening Statements\n",
        "        for role in [\"Prosecution Lawyer\", \"Defense Lawyer\"]:\n",
        "            if role in self.agents:\n",
        "                self.agents[role].respond(f\"Opening statement to the Court. Background: {self.case_background}\", verbose=verbose)\n",
        "\n",
        "        # Witness Interrogation & Argumentation\n",
        "        if verbose:\n",
        "            print(\"\\n==== Witness Interrogation & Argumentation ====\")\n",
        "\n",
        "        if \"Witness\" in self.agents:\n",
        "            witness_testimony = self.agents[\"Witness\"].respond(f\"Provide your testimony based on the case: {self.case_background}\", verbose=verbose)\n",
        "            self.agents[\"Prosecution Lawyer\"].respond(\"Cross-examine the witness based on their testimony.\", verbose=verbose)\n",
        "            self.agents[\"Defense Lawyer\"].respond(\"Cross-examine the witness based on their testimony.\", verbose=verbose)\n",
        "        else:\n",
        "            self.agents[\"Prosecution Lawyer\"].respond(\"Present your argument based on the case.\", verbose=verbose)\n",
        "            self.agents[\"Defense Lawyer\"].respond(\"Present your argument in response to the prosecution.\", verbose=verbose)\n",
        "\n",
        "        # Plaintiff and Defendant Statements\n",
        "        if verbose:\n",
        "            print(\"\\n==== Plaintiff and Defendant Statements ====\")\n",
        "\n",
        "        if \"Plaintiff\" in self.agents:\n",
        "            self.agents[\"Plaintiff\"].respond(\"Share your version of events.\", verbose=verbose)\n",
        "        if \"Defendant\" in self.agents:\n",
        "            self.agents[\"Defendant\"].respond(\"Respond to the accusations.\", verbose=verbose)\n",
        "\n",
        "        # Expert Consultant (if spawned)\n",
        "        if \"Expert Consultant\" in self.agents:\n",
        "            if verbose:\n",
        "                print(\"\\n==== Expert Consultant Testimony ====\")\n",
        "            self.agents[\"Expert Consultant\"].respond(f\"Provide expert analysis based on the case: {self.case_background}\", verbose=verbose)\n",
        "\n",
        "        # Closing Statements\n",
        "        if verbose:\n",
        "            print(\"\\n==== Closing Statements ====\")\n",
        "\n",
        "        for role in [\"Prosecution Lawyer\", \"Defense Lawyer\"]:\n",
        "            if role in self.agents:\n",
        "                self.agents[role].respond(\"Give your closing arguments.\", verbose=verbose)\n",
        "\n",
        "        # Judge's Verdict\n",
        "        if verbose:\n",
        "            print(\"\\n==== Judge's Verdict ====\")\n",
        "\n",
        "        judge_verdict = self.agents[\"Judge\"].respond(\"Based on all statements and testimonies, give your final verdict. Remember to end with FINAL VERDICT: [GRANTED/DENIED]\", verbose=verbose)\n",
        "        verdict_code = self.extract_verdict(judge_verdict)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\nVerdict code: {verdict_code} (1=GRANTED, 0=DENIED)\")\n",
        "\n",
        "        # Dismiss optional agents\n",
        "        for role in list(self.agents.keys()):\n",
        "            self.dismiss_agent(role)\n",
        "\n",
        "        return verdict_code\n",
        "\n",
        "# === Process CSV File and Generate Predictions (First 50 Cases) ===\n",
        "def process_csv_cases(csv_path: str, output_path: str = \"verdict_predictions.csv\", max_cases: int = 50):\n",
        "    \"\"\"Process the first specified number of cases from a CSV file and output predictions.\"\"\"\n",
        "    try:\n",
        "        # Load the CSV file\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        # Limit to first max_cases\n",
        "        df = df.head(max_cases)\n",
        "\n",
        "        # Prepare the results dataframe\n",
        "        results = []\n",
        "\n",
        "        # Process each case\n",
        "        for index, row in df.iterrows():\n",
        "            case_id = row['id']  # Using 'id' column from CSV\n",
        "            case_background = row['text']  # Using 'text' column from CSV\n",
        "\n",
        "            # Determine if this is the second case (to show conversation)\n",
        "            is_second_case = index == 1  # Python uses 0-based indexing, so second case is index 1\n",
        "\n",
        "            # Print info for all cases\n",
        "            print(f\"Processing case {case_id} ({index+1}/{len(df)})...\")\n",
        "\n",
        "            # Run the courtroom simulation\n",
        "            trial = CourtroomSimulation(case_background)\n",
        "            verdict = trial.run_trial(verbose=is_second_case)  # Only verbose for second case\n",
        "\n",
        "            # Add to results\n",
        "            results.append({\n",
        "                'ID': case_id,\n",
        "                'VERDICT': verdict\n",
        "            })\n",
        "\n",
        "            print(f\"Case {case_id} verdict: {verdict}\")\n",
        "\n",
        "        # Create and save the output dataframe\n",
        "        results_df = pd.DataFrame(results)\n",
        "        results_df.to_csv(output_path, index=False)\n",
        "        print(f\"Predictions saved to {output_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing CSV file: {e}\")\n",
        "\n",
        "# === Run the Predictor ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Usage:\n",
        "    csv_file_path = \"/content/cases.csv\"  # Replace with actual path\n",
        "    process_csv_cases(csv_file_path, max_cases=50)  # Process only first 50 cases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxEUr8H47Xkn",
        "outputId": "99a3cd68-aeba-4e9a-a6ea-181271364397"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing case 1989_75 (1/50)...\n",
            "Error processing CSV file: 402 Client Error: Payment Required for url: https://router.huggingface.co/hf-inference/models/mistralai/Mistral-7B-v0.3 (Request ID: Root=1-6803e779-5337549a01ea71cd47b3ef3e;dedadf42-9e45-4acd-939d-f94ae383a946)\n",
            "\n",
            "You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwFJuWMXHin6",
        "outputId": "ec14886f-85d8-4a60-9690-5973d24996b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.22.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
            "Downloading groq-0.22.0-py3-none-any.whl (126 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Optional\n",
        "from groq import Groq\n",
        "\n",
        "\n",
        "# === Generic Agent Class ===\n",
        "class CourtroomAgent:\n",
        "    def __init__(self,\n",
        "                 name: str,\n",
        "                 system_prompt: str,\n",
        "                 groq_api_key: str,\n",
        "                 model: str = \"llama3-8b-8192\"):\n",
        "        self.name = name\n",
        "        self.system_prompt = system_prompt.strip()\n",
        "        self.history: List[Dict[str, str]] = []      # list of {\"role\": ..., \"content\": ...}\n",
        "        self.client = Groq(\n",
        "            api_key=groq_api_key\n",
        "        )\n",
        "        self.model = model\n",
        "\n",
        "    def _format_prompt(self, user_msg: str) -> List[Dict[str, str]]:\n",
        "        messages = [{\"role\": \"system\", \"content\": self.system_prompt}]\n",
        "        # Limit history to last 2 messages to prevent token overflow\n",
        "        messages.extend(self.history[-2:])  # Keep only the most recent user-assistant pair\n",
        "        messages.append({\"role\": \"user\", \"content\": user_msg})\n",
        "\n",
        "        return messages\n",
        "\n",
        "    def respond(self, user_msg: str, **gen_kwargs) -> str:\n",
        "        # Truncate user message to 1000 characters to control input size\n",
        "        user_msg = user_msg[:1000]\n",
        "        messages = self._format_prompt(user_msg)\n",
        "        try:\n",
        "            completion = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=messages,\n",
        "                max_tokens=512,\n",
        "                temperature=0.7,\n",
        "                **gen_kwargs\n",
        "            )\n",
        "            answer = completion.choices[0].message.content.strip()\n",
        "            self.history.append({\"role\": \"user\", \"content\": user_msg})\n",
        "            self.history.append({\"role\": \"assistant\", \"content\": answer})\n",
        "\n",
        "            return answer\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating response for {self.name}: {e}\")\n",
        "            return \"Error: Unable to generate response.\"\n",
        "\n",
        "# === Role Registry ===\n",
        "ROLE_REGISTRY = {\n",
        "    \"Defendant\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are the *Defendant*.\n",
        "Goals:\n",
        "• Present your side truthfully and calmly.\n",
        "• Refute allegations based on your experience and recollection.\n",
        "Style:\n",
        "• Honest, composed, assertive when needed.\n",
        "Ethics:\n",
        "• Speak only based on your memory and beliefs. Do not lie.\n",
        "\"\"\",\n",
        "        \"required\": True\n",
        "    },\n",
        "    \"Defense Lawyer\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are lead *defense counsel*.\n",
        "Goals:\n",
        "• Protect the constitutional rights of the defendant.\n",
        "• Raise reasonable doubt by pointing out missing evidence or alternative explanations.\n",
        "• Be respectful to the Court and to opposing counsel.\n",
        "Style:\n",
        "• Crisp, persuasive, grounded in precedent and facts provided.\n",
        "• When citing precedent: give short case name + year (e.g., *Miranda v. Arizona* (1966)).\n",
        "Ethics:\n",
        "• Do not fabricate evidence; admit uncertainty when required.\n",
        "\"\"\",\n",
        "        \"required\": True\n",
        "    },\n",
        "    \"Plaintiff\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are the *Plaintiff*.\n",
        "Goals:\n",
        "• Share your account of the incident in a clear and compelling manner.\n",
        "Style:\n",
        "• Personal, emotional, but grounded in facts.\n",
        "Ethics:\n",
        "• Tell the truth as you experienced it.\n",
        "\"\"\",\n",
        "        \"required\": True\n",
        "    },\n",
        "    \"Prosecution Lawyer\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are *Assistant District Attorney* for the State.\n",
        "Goals:\n",
        "• Present the strongest good-faith case against the accused.\n",
        "• Lay out facts logically, citing exhibits or witness statements when available.\n",
        "• Anticipate and rebut common defense arguments.\n",
        "Style:\n",
        "• Formal but plain English; persuasive, with confident tone.\n",
        "Ethics:\n",
        "• Duty is to justice, not merely to win. Concede points when ethically required.\n",
        "\"\"\",\n",
        "        \"required\": True\n",
        "    },\n",
        "    \"Judge\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are the presiding *Judge*.\n",
        "Goals:\n",
        "• Ensure a fair trial by evaluating the arguments, facts, and testimonies.\n",
        "• Make rational, legally sound rulings.\n",
        "Style:\n",
        "• Calm, authoritative, impartial.\n",
        "Ethics:\n",
        "• Maintain judicial neutrality and decorum at all times.\n",
        "At the end of your verdict, you must clearly state whether the case is GRANTED or DENIED. Use exactly this format at the end of your verdict: \"FINAL VERDICT: [GRANTED/DENIED]\"\n",
        "\"\"\",\n",
        "        \"required\": True\n",
        "    },\n",
        "    \"Witness\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are a *Witness* in the trial.\n",
        "Goals:\n",
        "• Provide truthful testimony based on your knowledge of the case.\n",
        "• Answer questions clearly and concisely.\n",
        "Style:\n",
        "• Neutral, factual, cooperative.\n",
        "Ethics:\n",
        "• Do not speculate or lie; stick to what you know.\n",
        "\"\"\",\n",
        "        \"required\": False,\n",
        "        \"spawn_condition\": \"witness\"\n",
        "    },\n",
        "    \"Expert Consultant\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are an *Expert Consultant* providing specialized knowledge.\n",
        "Goals:\n",
        "• Offer objective, evidence-based insights relevant to the case.\n",
        "• Explain complex topics clearly for the court.\n",
        "Style:\n",
        "• Professional, precise, academic.\n",
        "Ethics:\n",
        "• Remain impartial and avoid advocating for either side.\n",
        "\"\"\",\n",
        "        \"required\": False,\n",
        "        \"spawn_condition\": \"expert\"\n",
        "    },\n",
        "    \"Bailiff\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are the *Bailiff*.\n",
        "Goals:\n",
        "• Maintain courtroom order and assist the judge as needed.\n",
        "• Announce trial phases or call witnesses.\n",
        "Style:\n",
        "• Formal, direct, procedural.\n",
        "Ethics:\n",
        "• Follow court protocol strictly.\n",
        "\"\"\",\n",
        "        \"required\": False,\n",
        "        \"spawn_condition\": \"procedural\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# === Courtroom Simulation ===\n",
        "class CourtroomSimulation:\n",
        "    def __init__(self, case_background: str, groq_api_key: str):\n",
        "        self.case_background = case_background\n",
        "        self.groq_api_key = groq_api_key\n",
        "        self.agents: Dict[str, CourtroomAgent] = {}\n",
        "        self.initialize_agents()\n",
        "        self.verdict = None\n",
        "\n",
        "    def initialize_agents(self):\n",
        "        \"\"\"Initialize required agents and dynamically spawn optional ones based on case.\"\"\"\n",
        "        # Spawn required agents\n",
        "        for role, config in ROLE_REGISTRY.items():\n",
        "            if config[\"required\"]:\n",
        "                self.agents[role] = CourtroomAgent(\n",
        "                    name=role,\n",
        "                    system_prompt=config[\"system_prompt\"],\n",
        "                    groq_api_key=self.groq_api_key\n",
        "                )\n",
        "\n",
        "        # Analyze case for optional roles\n",
        "        self.spawn_optional_agents()\n",
        "\n",
        "    def spawn_optional_agents(self):\n",
        "        \"\"\"Dynamically spawn optional agents based on case background.\"\"\"\n",
        "        case_lower = self.case_background.lower()\n",
        "        for role, config in ROLE_REGISTRY.items():\n",
        "            if not config[\"required\"] and role not in self.agents:\n",
        "                spawn_condition = config.get(\"spawn_condition\", \"\")\n",
        "                if spawn_condition in case_lower:\n",
        "                    self.agents[role] = CourtroomAgent(\n",
        "                        name=role,\n",
        "                        system_prompt=config[\"system_prompt\"],\n",
        "                        groq_api_key=self.groq_api_key\n",
        "                    )\n",
        "\n",
        "    def dismiss_agent(self, role: str):\n",
        "        \"\"\"Dismiss an agent when no longer needed.\"\"\"\n",
        "        if role in self.agents and not ROLE_REGISTRY[role][\"required\"]:\n",
        "            del self.agents[role]\n",
        "\n",
        "    def extract_verdict(self, judge_verdict: str) -> int:\n",
        "        \"\"\"Extract the binary verdict (GRANTED=1/DENIED=0) from the judge's text.\"\"\"\n",
        "        # Look for the FINAL VERDICT pattern\n",
        "        verdict_match = re.search(r\"FINAL VERDICT:\\s*(GRANTED|DENIED)\", judge_verdict, re.IGNORECASE)\n",
        "        if verdict_match:\n",
        "            verdict_text = verdict_match.group(1).upper()\n",
        "            return 1 if verdict_text == \"GRANTED\" else 0\n",
        "\n",
        "        # If no clear pattern, look for key mentions\n",
        "        if \"granted\" in judge_verdict.lower():\n",
        "            return 1\n",
        "        elif \"denied\" in judge_verdict.lower():\n",
        "            return 0\n",
        "\n",
        "        # If still no clear verdict, use a more sophisticated analysis\n",
        "        # Count positive vs negative sentiment words\n",
        "        positive_terms = [\"granted\", \"approve\", \"in favor\", \"plaintiff wins\", \"rule for plaintiff\"]\n",
        "        negative_terms = [\"denied\", \"reject\", \"dismiss\", \"defendant wins\", \"rule for defendant\"]\n",
        "\n",
        "        positive_count = sum(judge_verdict.lower().count(term) for term in positive_terms)\n",
        "        negative_count = sum(judge_verdict.lower().count(term) for term in negative_terms)\n",
        "\n",
        "        return 1 if positive_count > negative_count else 0\n",
        "\n",
        "    def run_trial(self) -> tuple:\n",
        "        \"\"\"Run the trial with no verbose output and return binary verdict and judge's full verdict.\"\"\"\n",
        "        # Opening Statements\n",
        "        for role in [\"Prosecution Lawyer\", \"Defense Lawyer\"]:\n",
        "            if role in self.agents:\n",
        "                self.agents[role].respond(f\"Opening statement to the Court. Background: {self.case_background}\")\n",
        "\n",
        "        # Witness Interrogation & Argumentation\n",
        "        if \"Witness\" in self.agents:\n",
        "            witness_testimony = self.agents[\"Witness\"].respond(f\"Provide your testimony based on the case: {self.case_background}\")\n",
        "            self.agents[\"Prosecution Lawyer\"].respond(\"Cross-examine the witness based on their testimony.\")\n",
        "            self.agents[\"Defense Lawyer\"].respond(\"Cross-examine the witness based on their testimony.\")\n",
        "        else:\n",
        "            self.agents[\"Prosecution Lawyer\"].respond(\"Present your argument based on the case.\")\n",
        "            self.agents[\"Defense Lawyer\"].respond(\"Present your argument in response to the prosecution.\")\n",
        "\n",
        "        # Plaintiff and Defendant Statements\n",
        "        if \"Plaintiff\" in self.agents:\n",
        "            self.agents[\"Plaintiff\"].respond(\"Share your version of events.\")\n",
        "        if \"Defendant\" in self.agents:\n",
        "            self.agents[\"Defendant\"].respond(\"Respond to the accusations.\")\n",
        "\n",
        "        # Expert Consultant (if spawned)\n",
        "        if \"Expert Consultant\" in self.agents:\n",
        "            self.agents[\"Expert Consultant\"].respond(f\"Provide expert analysis based on the case: {self.case_background}\")\n",
        "\n",
        "        # Closing Statements\n",
        "        for role in [\"Prosecution Lawyer\", \"Defense Lawyer\"]:\n",
        "            if role in self.agents:\n",
        "                self.agents[role].respond(\"Give your closing arguments.\")\n",
        "\n",
        "        # Judge's Verdict\n",
        "        judge_verdict = self.agents[\"Judge\"].respond(\"Based on all statements and testimonies, give your final verdict. Remember to end with FINAL VERDICT: [GRANTED/DENIED]\")\n",
        "        verdict_code = self.extract_verdict(judge_verdict)\n",
        "\n",
        "        # Dismiss optional agents\n",
        "        for role in list(self.agents.keys()):\n",
        "            self.dismiss_agent(role)\n",
        "\n",
        "        return verdict_code, judge_verdict\n",
        "\n",
        "# === Process CSV File and Generate Predictions (First 50 Cases) ===\n",
        "def process_csv_cases(csv_path: str, groq_api_key: str, output_path: str = \"verdict_predictions.csv\", verdicts_path: str = \"judge_verdicts.txt\", max_cases: int = 50):\n",
        "    \"\"\"Process the first specified number of cases from a CSV file and output predictions and judge verdicts.\"\"\"\n",
        "    try:\n",
        "        # Load the CSV file\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        # Limit to first max_cases\n",
        "        df = df.head(max_cases)\n",
        "\n",
        "        # Prepare the results dataframe and verdicts file\n",
        "        results = []\n",
        "        verdicts_file = open(verdicts_path, \"w\", encoding=\"utf-8\")\n",
        "\n",
        "        # Process each case\n",
        "        for index, row in df.iterrows():\n",
        "            case_id = row['id']  # Using 'id' column from CSV\n",
        "            case_background = row['text']  # Using 'text' column from CSV\n",
        "\n",
        "            print(f\"Processing case {case_id} ({index+1}/{len(df)})...\")\n",
        "\n",
        "            # Run the courtroom simulation\n",
        "            trial = CourtroomSimulation(case_background, groq_api_key)\n",
        "            verdict_code, judge_verdict = trial.run_trial()\n",
        "\n",
        "            # Add to results\n",
        "            results.append({\n",
        "                'ID': case_id,\n",
        "                'VERDICT': verdict_code\n",
        "            })\n",
        "\n",
        "            # Save the judge's full verdict to the file\n",
        "            verdicts_file.write(f\"=== CASE {case_id} ===\\n\")\n",
        "            verdicts_file.write(f\"{judge_verdict}\\n\\n\")\n",
        "\n",
        "            # Only print the verdict code\n",
        "            print(f\"Case {case_id} verdict: {verdict_code} (1=GRANTED, 0=DENIED)\")\n",
        "\n",
        "        # Close the verdicts file\n",
        "        verdicts_file.close()\n",
        "\n",
        "        # Create and save the output dataframe\n",
        "        results_df = pd.DataFrame(results)\n",
        "        results_df.to_csv(output_path, index=False)\n",
        "        print(f\"Predictions saved to {output_path}\")\n",
        "        print(f\"Judge verdicts saved to {verdicts_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing CSV file: {e}\")\n",
        "\n",
        "# === Run the Predictor ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Set your Groq API key directly here\n",
        "    groq_api_key = \"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\"  # Replace with your actual API key\n",
        "\n",
        "    # Alternatively, you can set it as an environment variable before running the script:\n",
        "    # import os\n",
        "    # os.environ[\"GROQ_API_KEY\"] = \"your-api-key\"\n",
        "    # groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "    # Usage:\n",
        "    csv_file_path = \"/content/cases.csv\"  # Replace with actual path\n",
        "    process_csv_cases(csv_file_path, groq_api_key, max_cases=50)  # Process only first 50 cases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6RjCDlHKpHm",
        "outputId": "783e5958-722c-4f4d-e94e-fd8794f619b3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing case 1989_75 (1/50)...\n",
            "Case 1989_75 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1959_102 (2/50)...\n",
            "Case 1959_102 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1979_76 (3/50)...\n",
            "Case 1979_76 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1991_124 (4/50)...\n",
            "Case 1991_124 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1985_233 (5/50)...\n",
            "Case 1985_233 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1984_73 (6/50)...\n",
            "Case 1984_73 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1963_191 (7/50)...\n",
            "Case 1963_191 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1992_1 (8/50)...\n",
            "Case 1992_1 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1963_285 (9/50)...\n",
            "Case 1963_285 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1961_166 (10/50)...\n",
            "Case 1961_166 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1962_237 (11/50)...\n",
            "Case 1962_237 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1990_342 (12/50)...\n",
            "Case 1990_342 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1975_183 (13/50)...\n",
            "Case 1975_183 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1985_23 (14/50)...\n",
            "Case 1985_23 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1988_248 (15/50)...\n",
            "Case 1988_248 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1971_570 (16/50)...\n",
            "Case 1971_570 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1984_63 (17/50)...\n",
            "Case 1984_63 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1954_181 (18/50)...\n",
            "Case 1954_181 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1988_201 (19/50)...\n",
            "Case 1988_201 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1967_162 (20/50)...\n",
            "Case 1967_162 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1958_67 (21/50)...\n",
            "Case 1958_67 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1983_89 (22/50)...\n",
            "Case 1983_89 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1971_338 (23/50)...\n",
            "Case 1971_338 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1969_369 (24/50)...\n",
            "Case 1969_369 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1977_0 (25/50)...\n",
            "Case 1977_0 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1971_138 (26/50)...\n",
            "Case 1971_138 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1983_169 (27/50)...\n",
            "Case 1983_169 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1977_200 (28/50)...\n",
            "Case 1977_200 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1960_229 (29/50)...\n",
            "Case 1960_229 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1977_103 (30/50)...\n",
            "Case 1977_103 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1968_179 (31/50)...\n",
            "Case 1968_179 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1966_153 (32/50)...\n",
            "Case 1966_153 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1968_350 (33/50)...\n",
            "Case 1968_350 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1976_40 (34/50)...\n",
            "Case 1976_40 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1961_431 (35/50)...\n",
            "Case 1961_431 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1979_446 (36/50)...\n",
            "Case 1979_446 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1980_164 (37/50)...\n",
            "Case 1980_164 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1961_123 (38/50)...\n",
            "Case 1961_123 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1974_386 (39/50)...\n",
            "Case 1974_386 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1978_306 (40/50)...\n",
            "Case 1978_306 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1977_120 (41/50)...\n",
            "Case 1977_120 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1958_49 (42/50)...\n",
            "Case 1958_49 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1991_142 (43/50)...\n",
            "Case 1991_142 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1974_86 (44/50)...\n",
            "Case 1974_86 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1966_269 (45/50)...\n",
            "Case 1966_269 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1975_38 (46/50)...\n",
            "Case 1975_38 verdict: 0 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1965_327 (47/50)...\n",
            "Case 1965_327 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1986_422 (48/50)...\n",
            "Case 1986_422 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1968_86 (49/50)...\n",
            "Case 1968_86 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Processing case 1982_6 (50/50)...\n",
            "Case 1982_6 verdict: 1 (1=GRANTED, 0=DENIED)\n",
            "Predictions saved to verdict_predictions.csv\n",
            "Judge verdicts saved to judge_verdicts.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W--qoV8gKpKw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}